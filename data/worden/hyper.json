{"params": [{"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "2", "net__hidden_type": "GRU", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "2", "net__hidden_type": "GRU", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "2", "net__hidden_type": "GRU", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "2", "net__hidden_type": "GRU", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "2", "net__hidden_type": "GRU", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "2", "net__hidden_type": "GRU", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "2", "net__hidden_type": "GRU", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "2", "net__hidden_type": "GRU", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "2", "net__hidden_type": "LSTM", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "2", "net__hidden_type": "LSTM", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "2", "net__hidden_type": "LSTM", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "2", "net__hidden_type": "LSTM", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "2", "net__hidden_type": "LSTM", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "2", "net__hidden_type": "LSTM", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "2", "net__hidden_type": "LSTM", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "2", "net__hidden_type": "LSTM", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "3", "net__hidden_type": "GRU", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "3", "net__hidden_type": "GRU", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "3", "net__hidden_type": "GRU", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "3", "net__hidden_type": "GRU", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "3", "net__hidden_type": "GRU", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "3", "net__hidden_type": "GRU", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "3", "net__hidden_type": "GRU", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "3", "net__hidden_type": "GRU", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "3", "net__hidden_type": "LSTM", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "3", "net__hidden_type": "LSTM", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "3", "net__hidden_type": "LSTM", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "3", "net__hidden_type": "LSTM", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "3", "net__hidden_type": "LSTM", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "3", "net__hidden_type": "LSTM", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "3", "net__hidden_type": "LSTM", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "128", "net__layers_num": "3", "net__hidden_type": "LSTM", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "2", "net__hidden_type": "GRU", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "2", "net__hidden_type": "GRU", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "2", "net__hidden_type": "GRU", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "2", "net__hidden_type": "GRU", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "2", "net__hidden_type": "GRU", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "2", "net__hidden_type": "GRU", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "2", "net__hidden_type": "GRU", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "2", "net__hidden_type": "GRU", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "2", "net__hidden_type": "LSTM", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "2", "net__hidden_type": "LSTM", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "2", "net__hidden_type": "LSTM", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "2", "net__hidden_type": "LSTM", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "2", "net__hidden_type": "LSTM", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "2", "net__hidden_type": "LSTM", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "2", "net__hidden_type": "LSTM", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "2", "net__hidden_type": "LSTM", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "3", "net__hidden_type": "GRU", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "3", "net__hidden_type": "GRU", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "3", "net__hidden_type": "GRU", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "3", "net__hidden_type": "GRU", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "3", "net__hidden_type": "GRU", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "3", "net__hidden_type": "GRU", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "3", "net__hidden_type": "GRU", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "3", "net__hidden_type": "GRU", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "3", "net__hidden_type": "LSTM", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "3", "net__hidden_type": "LSTM", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "3", "net__hidden_type": "LSTM", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "3", "net__hidden_type": "LSTM", "net__dropout_prob": "0.1", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "3", "net__hidden_type": "LSTM", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "3", "net__hidden_type": "LSTM", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "3", "net__hidden_type": "LSTM", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "0.0001", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}, {"net": "<class 'src.network.worden.Worden'>", "net__vocab_size": "10680", "net__embedding_dim": "100", "net__trained_embeddings": "tensor([[ 0.2235, -0.0750,  0.2944,  ...,  0.1127, -0.0076, -0.1203],\n        [-0.6752, -0.2077, -0.1711,  ...,  0.0623,  0.0174, -0.5472],\n        [ 0.3847,  0.4935,  0.4910,  ...,  0.0263,  0.3905,  0.5222],\n        ...,\n        [ 0.2671,  0.2247, -0.3181,  ..., -0.9860, -0.0759,  0.8073],\n        [ 0.2586, -0.2388, -0.3078,  ..., -0.0346, -0.1336,  0.3431],\n        [-0.7181,  0.5626, -0.9680,  ..., -0.7121, -0.3024,  0.9836]])", "net__freeze_embeddings": "False", "net__hidden_units": "256", "net__layers_num": "3", "net__hidden_type": "LSTM", "net__dropout_prob": "0.3", "optim": "<class 'torch.optim.adam.Adam'>", "lr": "0.0001", "optim__weight_decay": "1e-05", "loss_fn": "<class 'torch.nn.modules.loss.CrossEntropyLoss'>"}], "train_losses": [[8.068729718526205, 6.309574321464256, 6.164284741436994, 6.1318547990587025, 6.046213432594582, 6.11052166974103, 6.031523616225631, 6.019068223458749, 5.910947110917833, 5.936900792298494], [7.869384341769749, 6.287946789352982, 6.125842324009648, 6.125623296808313, 6.152668846978082, 6.172618795324255, 6.198522532427752, 6.0881943172878685, 6.055052704281277, 6.045594533284505], [7.953423553042942, 6.199293366184941, 6.165520862296775, 6.194433300583451, 6.086253766660337, 6.0348860422770185, 6.0011302453500255, 5.986751026577419, 5.972501878385191, 5.940422958797878], [7.911317842978018, 6.274187547189218, 6.1893524946989835, 6.162245467857078, 6.164715113463225, 6.093061341179742, 6.093006911101164, 6.038876003689236, 6.005446539984809, 5.951995443414758], [7.882368070107919, 6.188304865801776, 6.015611136401141, 6.133409270533809, 6.052252557542589, 6.06363238228692, 5.985260204032615, 6.0118654745596425, 5.976450973086887, 5.872343840422453], [7.774554146660699, 6.224176777733697, 6.071011031115496, 6.121686511569553, 6.169329696231419, 6.1191728733204025, 6.127094745635986, 6.025647604907, 5.998381526381881, 6.062356860549362], [7.950885437153004, 6.214013346919307, 6.152116793173331, 6.142019324832493, 6.062049671455666, 5.992356141408284, 5.94836229748196, 5.974516444736057, 5.987196357161911, 6.056029531690809], [7.837066509105541, 6.223493893941243, 6.137707003840694, 6.1070711171185526, 6.192960792117649, 6.112668761500606, 6.0823919861404985, 6.028594299598977, 5.9625416155214666, 5.8344065348307295], [8.068901892061588, 6.2309375339084205, 6.25814927065814, 6.190845719090214, 6.022030936347114, 6.121845421967683, 5.9722208976745605, 6.0133294882597745, 6.027737334922508, 6.009524857556379], [7.972257031334771, 6.233207755618626, 6.248921941827844, 6.174113944724754, 6.182356498859547, 6.119557751549615, 5.981174009817618, 6.035670774954337, 6.078682051764594, 5.891972736076072], [8.028656623981616, 6.325574221434416, 6.267923884921604, 6.158108375690602, 6.188858950579608, 6.099322319030762, 5.886438352090341, 5.992820775067365, 6.018884446885851, 6.040169186062283], [7.9535679463986995, 6.272985829247369, 6.212986822481509, 6.095955972318296, 6.1493696989836515, 6.043899200580738, 5.971376825261999, 6.003409350359881, 6.002417264161287, 6.01119163301256], [8.168665250142416, 6.3279384153860585, 6.243359283164695, 6.16225023622866, 5.99741812105532, 6.0095391273498535, 5.950988328015363, 6.040119612658465, 6.013170489558467, 6.017337145628752], [8.064486556582981, 6.320499437826651, 6.15303897857666, 6.158485218330666, 6.047267083768491, 6.088807282624422, 6.036218413600215, 5.984351087499548, 6.027466191185845, 6.037470411371301], [8.149488360793502, 6.223465972476536, 6.170453371825041, 6.1101175237584995, 5.97358821939539, 6.066748566097683, 6.035914933239972, 6.068331259268302, 6.019352824599655, 5.982380266542788], [8.183425656071416, 6.188793023427327, 6.087480880596019, 6.086075076350459, 6.158733615168819, 5.995253192053901, 6.015310216833044, 6.108009497324626, 6.072774357265896, 5.924978415171306], [7.786205998173466, 6.265285686210349, 6.172162886019106, 6.045146694889775, 6.13412818202266, 6.025087321246112, 6.049971792432997, 6.016319539811876, 6.002283873381438, 6.040542478914614], [7.858618612642641, 6.173153170832881, 6.160874878918683, 6.139502136795609, 6.052112808933964, 6.146584916997839, 6.073180975737395, 6.0973356211626974, 5.997282769944933, 6.050819361651385], [7.757966094546848, 6.2359180803652166, 6.1983922675803855, 6.045982837677002, 6.042081691600658, 6.062046439559372, 6.09327076099537, 6.080683690530282, 6.075483110215929, 6.023314069818567], [7.833947040416576, 6.303093786592837, 6.160184189125344, 6.148356649610731, 6.184380637274848, 6.0728142879627365, 6.105951503471092, 6.038931511066578, 6.068721011832908, 6.0448205559342], [7.865080374258536, 6.256737815009223, 6.1772504029450594, 6.096352012069137, 6.069792765158194, 5.950012136388708, 6.0865587305139615, 6.091572108092131, 5.9827334969132036, 6.013883643680149], [7.831217836450647, 6.33666956866229, 6.1512491791336625, 6.078323593846074, 6.1815802432872635, 6.130088841473615, 6.084307458665636, 6.094054045500578, 6.146298037634955, 6.120836946699354], [7.900220411795157, 6.217849978694209, 6.183302720387776, 6.054353731649893, 5.9971807267930775, 6.066468062224211, 6.016031247598153, 5.968142968636972, 6.017499959027326, 6.017804428383156], [7.84566284109045, 6.341432023931433, 6.204656971825494, 6.145983731305158, 6.155463836811207, 6.115419493781196, 6.095634513431126, 6.0631894182275845, 6.050681485070123, 6.029230841883907], [8.040455076429579, 6.386823230319553, 6.1513346036275225, 6.1443783971998425, 6.005683616355613, 6.083449805224383, 6.073189205593533, 6.059561959019414, 6.011570806856509, 6.128275641688594], [8.201143070503518, 6.2555238052650735, 6.145580962852195, 6.113296632413511, 6.082024256388347, 6.006559177681252, 6.062592947924578, 6.0660939923039185, 5.994135591718885, 6.005820662887008], [8.116431183285183, 6.4286527986879705, 6.221568990636755, 6.166230184060556, 6.1451987160576715, 6.098718872776738, 6.042281839582655, 5.9622931480407715, 5.970450365984881, 6.014139793537281], [8.169084513628924, 6.2565095159742565, 6.247075027889675, 6.093656416292544, 6.092789455696389, 6.0749350830360695, 6.008851598810266, 6.025772236011647, 6.098076502482097, 6.055161175904451], [8.196801132626003, 6.372421776806867, 6.1979847837377475, 6.081972510726364, 6.0969466809873225, 6.058008211630362, 6.01868145554154, 5.9549145168728295, 6.008860535091824, 5.90148040983412], [8.007290751845748, 6.3202398088243275, 6.119027808860496, 6.24206002553304, 6.082584292800338, 5.994117807458948, 6.017441979161015, 6.055034867039433, 5.941879307782209, 5.960224999321832], [8.261556554723668, 6.245952765146892, 6.232121502911603, 6.094309312325937, 6.043374573742902, 6.042611440022786, 6.134950514192934, 5.993503464592828, 5.952735812575729, 5.934609554432057], [8.035808598553693, 6.333657635582818, 6.302403255745217, 6.122191464459455, 6.006987271485506, 5.975130593335187, 6.144414389574969, 6.103981000405771, 6.017444716559516, 6.06367411436858], [7.314865659784387, 6.389435556199816, 6.184674457267478, 6.106124083201091, 6.1198676250599044, 6.094195577833387, 6.091932702947546, 6.121399067066334, 6.105654910758689, 6.026856969904016], [7.192211857548466, 6.403486958256474, 6.242225558669479, 6.294958149945295, 6.182813873997441, 6.22368319829305, 6.218312493077031, 6.13122378455268, 6.117695684786196, 6.117819591804787], [7.389521386888292, 6.337922166894983, 6.20894933629919, 6.265763000205711, 6.100821848268862, 6.038748705828631, 6.1385008140846535, 6.10887011775264, 6.041966879809344, 5.995818650280988], [7.229662012170862, 6.526034867322004, 6.314792138558847, 6.2735973640724465, 6.27033950664379, 6.223628450323035, 6.137422543984872, 6.052850405375163, 6.213231298658583, 6.160363091362847], [7.2845647599962025, 6.419930193159315, 6.3306770148100675, 6.079266124301487, 6.165947066413032, 6.119832197825114, 6.10582575974641, 6.1885189833464445, 6.03214548252247, 5.897915063080965], [7.273266262478298, 6.446302996741401, 6.2806393835279675, 6.282682736714681, 6.318819452215124, 6.1354586459972245, 6.260379084834346, 6.173730956183539, 6.094386665909378, 6.099990597477666], [7.2945069207085504, 6.450152485458939, 6.195906321207683, 6.285143569663719, 6.140983210669623, 6.035343382093641, 6.130262816393817, 6.071729200857657, 6.022812207539876, 6.062689675225152], [7.21871081104985, 6.449130588107639, 6.355634035887541, 6.254858829357006, 6.122718245894821, 6.146109333744755, 6.190831926133898, 6.058402326371935, 6.2213748296101885, 6.233125280450891], [7.414164790400752, 6.3414467529014305, 6.178566773732503, 6.081384800098561, 6.148368764806677, 6.042842335171169, 6.160574895364267, 5.971988324765806, 6.080186314053005, 6.041142516665989], [7.392572420614737, 6.330365022023519, 6.144905602490461, 6.184735933939616, 6.14745729940909, 6.146724577303286, 6.097380020000316, 6.074305393077709, 6.073755723458749, 5.948952251010471], [7.444333853545012, 6.461676085436785, 6.288182876728199, 6.1074407365587025, 6.054203810515227, 6.066789026613589, 6.032441651379621, 5.996114660192419, 6.077023841716625, 5.957866350809733], [7.390269032231084, 6.4552479143495916, 6.255826120023374, 6.180913660261366, 6.116637123955621, 6.096538579022443, 6.147611317811189, 6.0197407051369, 6.015363304703324, 6.071772751984773], [7.385376965558088, 6.428467220730251, 6.217368549770779, 6.198574825569436, 6.112402191868535, 6.062612215677897, 5.925898587262189, 5.993181723135489, 5.951892111036512, 5.975965270289668], [7.456242614322239, 6.472682069849085, 6.183034508316605, 6.198452225437871, 6.09885060345685, 6.044413866820158, 6.036328457019947, 6.036224400555646, 6.117766698201497, 6.138173350581416], [7.428791311052111, 6.367142006202981, 6.0946263207329645, 6.012266441627785, 6.148090539155183, 6.091213049712004, 5.981714178014685, 6.0145594102365, 5.9827099906073675, 5.934316017009594], [7.446599960327148, 6.3885040283203125, 6.215565787421332, 6.191445385968244, 6.0801855193244085, 6.04338495819657, 6.040130774180095, 6.12146375797413, 6.061669084760878, 5.9902721687599465], [7.2754529493826405, 6.348048757623743, 6.210343413882786, 6.155735192475496, 6.1459028102733475, 6.135974089304606, 6.014096860532407, 6.153806121261032, 6.063068478195755, 6.0772079891628685], [7.302247612564652, 6.371773755108869, 6.241835894408049, 6.07876334366975, 6.228108247121175, 6.165127224392361, 6.271217752386023, 6.113511138492161, 6.1656521161397295, 6.163232591417101], [7.240836055190475, 6.348049570012976, 6.21927528028135, 6.33495408517343, 6.096026402932626, 6.047163256892452, 6.011374208662245, 6.1125461790296765, 6.010096620630335, 6.042192229518184], [7.253329347681116, 6.424822507081209, 6.248262334752966, 6.21133279800415, 6.127583433080603, 6.15796638418127, 6.1471257562990544, 6.204606497729266, 6.234035580246537, 6.133785830603705], [7.271529586226852, 6.276848828351056, 6.173460042035138, 6.169969629358362, 6.100945596341734, 6.0826452749746815, 6.088624300780119, 6.136582816088641, 6.129885337970875, 6.167065373173466], [7.269458399878608, 6.334113015068902, 6.320184354428892, 6.158859500178584, 6.095834414164226, 6.252185485981129, 6.202771734308313, 6.003889772627089, 6.27606345989086, 6.070141103532579], [7.284492863549127, 6.3664145116452815, 6.105481359693739, 6.140144454108344, 6.100168281131321, 6.055199693750452, 6.1130622934412076, 6.1481287920916525, 6.043491045633952, 6.145443050949662], [7.231281986942998, 6.313062597204138, 6.325219719498246, 6.249206560629386, 6.2488254617761685, 6.1315126772280095, 6.2197964809559005, 6.151286884590432, 6.0952141903064865, 6.09116503044411], [7.402893878795482, 6.344033912376121, 6.215082698398167, 6.0882316518712924, 6.128479215833876, 6.140899199026602, 6.030327461383961, 5.992663983945493, 5.958075452733923, 6.036685237178096], [7.425092538197835, 6.277202394273546, 6.255880673726399, 6.234881348080105, 6.143339227747034, 6.041788631015354, 6.1194732454088, 6.049801685191967, 6.0830404493543835, 6.1515224774678545], [7.411068898660165, 6.3588760693868, 6.162933261306198, 6.075966782040066, 6.126656426323785, 6.11183516184489, 6.027124828762478, 6.099486121424922, 6.106466240353054, 6.055581816920528], [7.4190742174784345, 6.423289917133473, 6.215078000669126, 6.154290605474402, 6.19702833670157, 6.11441437403361, 6.074331866370307, 6.076890998416477, 6.061541310063115, 6.065282751012732], [7.471827012521249, 6.314843707614475, 6.17709258750633, 6.149019329636185, 6.036378807491726, 5.923355632358128, 6.066621639110424, 6.006718723862259, 5.9495739407009545, 6.011168444598162], [7.526441362169054, 6.373376475440131, 6.187278041133174, 6.187653382619222, 6.080220981880471, 6.136674598411277, 6.030090349691886, 6.103563767892343, 5.9428476051048, 6.065910745550085], [7.510753331360994, 6.419234611369945, 6.199698253914162, 6.123597957469799, 6.098232498875371, 6.1357828069616245, 6.100752706880923, 6.104530122545031, 6.081416960115786, 6.030879744776973], [7.2634232838948565, 6.546331917798078, 6.2256011962890625, 6.2114382673192905, 6.1187242578577115, 6.037338963261357, 6.132138305240208, 6.085987320652714, 6.131282417862503, 6.113860801414207]], "train_times": [[2.3371083736419678, 2.302842855453491, 2.3277077674865723, 2.3537070751190186, 2.5259015560150146, 2.5088205337524414, 2.340290069580078, 2.304837942123413, 2.3044545650482178, 2.3268446922302246], [2.327357769012451, 2.312091827392578, 2.3035595417022705, 2.2960288524627686, 2.294119119644165, 2.29209041595459, 2.2974483966827393, 2.287341833114624, 2.2960972785949707, 2.3059470653533936], [2.296252489089966, 2.2909677028656006, 2.320815086364746, 2.3059003353118896, 2.320688247680664, 2.3282501697540283, 2.3000576496124268, 2.295240640640259, 2.2922563552856445, 2.308769941329956], [2.313375234603882, 2.3013100624084473, 2.320951461791992, 2.3038835525512695, 2.3122377395629883, 2.3211746215820312, 2.3559019565582275, 2.3436379432678223, 2.3348138332366943, 2.30608868598938], [2.3163092136383057, 2.3132214546203613, 2.3100907802581787, 2.31685471534729, 2.3377716541290283, 2.325653553009033, 2.3296449184417725, 2.306657552719116, 2.3017702102661133, 2.297635078430176], [2.313955307006836, 2.300736427307129, 2.3061277866363525, 2.315941095352173, 2.3114423751831055, 2.311462879180908, 2.32928204536438, 2.3217856884002686, 2.318183660507202, 2.314802885055542], [2.3324897289276123, 2.326716423034668, 2.333448648452759, 2.315822124481201, 2.3054697513580322, 2.3058974742889404, 2.3000400066375732, 2.3003883361816406, 2.3054652214050293, 2.294297695159912], [2.320465326309204, 2.327441453933716, 2.3264129161834717, 2.3172078132629395, 2.3084983825683594, 2.322377920150757, 2.3127341270446777, 2.3131823539733887, 2.305736780166626, 2.3085010051727295], [2.32497501373291, 2.3619306087493896, 2.3930861949920654, 2.454280138015747, 2.448530912399292, 2.3205699920654297, 2.3369505405426025, 2.3276946544647217, 2.3424971103668213, 2.324622631072998], [2.3154726028442383, 2.322101593017578, 2.3307254314422607, 2.3279709815979004, 2.337606906890869, 2.3298873901367188, 2.3226256370544434, 2.311312198638916, 2.320713520050049, 2.319319009780884], [2.325016975402832, 2.3009355068206787, 2.322002649307251, 2.322404146194458, 2.321016788482666, 2.319347381591797, 2.311511993408203, 2.3120155334472656, 2.320685386657715, 2.3233256340026855], [2.3138415813446045, 2.3020880222320557, 2.309612512588501, 2.297050952911377, 2.29661226272583, 2.3143975734710693, 2.295199394226074, 2.334691286087036, 2.3344521522521973, 2.3282458782196045], [2.3268587589263916, 2.3107056617736816, 2.3517205715179443, 2.336167335510254, 2.334261655807495, 2.323134422302246, 2.3119802474975586, 2.3081958293914795, 2.326881170272827, 2.320232391357422], [2.335318088531494, 2.3265280723571777, 2.3190906047821045, 2.3099873065948486, 2.3055264949798584, 2.313913583755493, 2.318619966506958, 2.3144259452819824, 2.3162736892700195, 2.3406524658203125], [2.322047472000122, 2.332786798477173, 2.322136640548706, 2.3101322650909424, 2.3006784915924072, 2.2967679500579834, 2.312913656234741, 2.325991630554199, 2.3206238746643066, 2.3197696208953857], [2.325765609741211, 2.3431854248046875, 2.333646297454834, 2.3413987159729004, 2.3343617916107178, 2.328953981399536, 2.3200604915618896, 2.329561948776245, 2.3184409141540527, 2.3153364658355713], [2.3977551460266113, 2.3946328163146973, 2.3665542602539062, 2.3653199672698975, 2.384989023208618, 2.37080717086792, 2.369081974029541, 2.3632988929748535, 2.3526012897491455, 2.3842520713806152], [2.38344669342041, 2.364023447036743, 2.3808555603027344, 2.369713544845581, 2.3918769359588623, 2.3810739517211914, 2.382549524307251, 2.386833906173706, 2.3656744956970215, 2.361952066421509], [2.3866958618164062, 2.370145559310913, 2.386596441268921, 2.3850631713867188, 2.4001708030700684, 2.372366428375244, 2.3910977840423584, 2.3914711475372314, 2.3702197074890137, 2.3823165893554688], [2.3828866481781006, 2.3804004192352295, 2.4006924629211426, 2.3914966583251953, 2.378758430480957, 2.3733484745025635, 2.383780002593994, 2.3889853954315186, 2.413115978240967, 2.4049534797668457], [2.395050048828125, 2.3698179721832275, 2.380845785140991, 2.384225368499756, 2.3842670917510986, 2.3745968341827393, 2.392594814300537, 2.3903565406799316, 2.3915369510650635, 2.3696985244750977], [2.383481502532959, 2.3906936645507812, 2.4515810012817383, 2.4150924682617188, 2.403791904449463, 2.425078868865967, 2.404961109161377, 2.374189615249634, 2.381774425506592, 2.3655996322631836], [2.374363899230957, 2.371281147003174, 2.3617637157440186, 2.3681676387786865, 2.359262466430664, 2.387179374694824, 2.3759799003601074, 2.3966598510742188, 2.376474142074585, 2.3709566593170166], [2.375609874725342, 2.389376401901245, 2.3756613731384277, 2.3703773021698, 2.3722128868103027, 2.4078750610351562, 2.3796355724334717, 2.3776040077209473, 2.3838372230529785, 2.380971908569336], [2.4044394493103027, 2.399198293685913, 2.394308090209961, 2.380249261856079, 2.40248441696167, 2.4007954597473145, 2.400357484817505, 2.379105567932129, 2.402212619781494, 2.384981632232666], [2.403017282485962, 2.408276319503784, 2.394127130508423, 2.4041905403137207, 2.38405179977417, 2.388643980026245, 2.39436674118042, 2.3847732543945312, 2.3896143436431885, 2.389960765838623], [2.3975110054016113, 2.3974199295043945, 2.403226137161255, 2.40466046333313, 2.4168241024017334, 2.4017679691314697, 2.388273000717163, 2.396009922027588, 2.3920955657958984, 2.4018871784210205], [2.4100096225738525, 2.395045280456543, 2.4174442291259766, 2.418853282928467, 2.4142584800720215, 2.402146339416504, 2.4121084213256836, 2.397554636001587, 2.41615891456604, 2.395951271057129], [2.406203031539917, 2.392592191696167, 2.3883845806121826, 2.396921157836914, 2.387836456298828, 2.393440008163452, 2.3846774101257324, 2.380621910095215, 2.3854732513427734, 2.3810617923736572], [2.397355079650879, 2.3841655254364014, 2.3997466564178467, 2.396718978881836, 2.400953769683838, 2.4001059532165527, 2.393623113632202, 2.4086811542510986, 2.398582935333252, 2.3818318843841553], [2.405703067779541, 2.398987293243408, 2.3956520557403564, 2.3924319744110107, 2.4044809341430664, 2.403482675552368, 2.401991367340088, 2.406416654586792, 2.4106903076171875, 2.41973614692688], [2.3926005363464355, 2.385610580444336, 2.396790027618408, 2.3962314128875732, 2.377411127090454, 2.3807849884033203, 2.3863887786865234, 2.3859505653381348, 2.3904967308044434, 2.3852076530456543], [2.570385694503784, 2.577202320098877, 2.584761142730713, 2.614833116531372, 2.5819740295410156, 2.556468963623047, 2.584099769592285, 2.5508384704589844, 2.576068639755249, 2.5625534057617188], [2.567293882369995, 2.5702357292175293, 2.5673396587371826, 2.5703887939453125, 2.590031147003174, 2.606214761734009, 2.5606613159179688, 2.58721923828125, 2.583601713180542, 2.578075885772705], [2.565253734588623, 2.555729389190674, 2.562059164047241, 2.5621650218963623, 2.5824804306030273, 2.570087432861328, 2.567434549331665, 2.579195022583008, 2.573291540145874, 2.5781452655792236], [2.5619547367095947, 2.5677316188812256, 2.583308219909668, 2.5803868770599365, 2.5716300010681152, 2.5742135047912598, 2.564073085784912, 2.576108455657959, 2.5608890056610107, 2.5804367065429688], [2.573000431060791, 2.560426712036133, 2.5657973289489746, 2.57295560836792, 2.5867996215820312, 2.5618045330047607, 2.5725905895233154, 2.5677530765533447, 2.5478949546813965, 2.5460188388824463], [2.555410146713257, 2.5646896362304688, 2.571758985519409, 2.570657968521118, 2.566455364227295, 2.5578601360321045, 2.5644562244415283, 2.5564303398132324, 2.5674221515655518, 2.5506982803344727], [2.561331033706665, 2.5560383796691895, 2.563518524169922, 2.5649354457855225, 2.5479040145874023, 2.5557267665863037, 2.554638147354126, 2.573035717010498, 2.5603697299957275, 2.5699708461761475], [2.584691047668457, 2.5987961292266846, 2.605987071990967, 2.571331262588501, 2.5883984565734863, 2.56486439704895, 2.593557596206665, 2.5600926876068115, 2.5580344200134277, 2.5738525390625], [2.5880014896392822, 2.5943996906280518, 2.584604501724243, 2.59521222114563, 2.596193790435791, 2.6034975051879883, 2.5853796005249023, 2.596897840499878, 2.6050076484680176, 2.604963779449463], [2.603874444961548, 2.6212921142578125, 2.6261203289031982, 2.6174731254577637, 2.647921323776245, 2.609114646911621, 2.608349561691284, 2.612154960632324, 2.5906119346618652, 2.596763849258423], [2.601163864135742, 2.60972261428833, 2.596780300140381, 2.5794079303741455, 2.5890862941741943, 2.580605983734131, 2.5927743911743164, 2.5870604515075684, 2.5767338275909424, 2.603832244873047], [2.589250326156616, 2.595054864883423, 2.6026227474212646, 2.6162526607513428, 2.6122591495513916, 2.596285104751587, 2.6107869148254395, 2.611368179321289, 2.63281512260437, 2.6136348247528076], [2.630754232406616, 2.636035680770874, 2.5988433361053467, 2.623992681503296, 2.6166021823883057, 2.60750412940979, 2.6001012325286865, 2.6174988746643066, 2.6037158966064453, 2.615508556365967], [2.6072208881378174, 2.6169092655181885, 2.615163564682007, 2.616919994354248, 2.6156511306762695, 2.6159708499908447, 2.592799186706543, 2.597036123275757, 2.608618974685669, 2.6202521324157715], [2.6053824424743652, 2.609344959259033, 2.612955331802368, 2.588129997253418, 2.5898303985595703, 2.598306179046631, 2.5960264205932617, 2.585336923599243, 2.60044002532959, 2.611147165298462], [2.6018025875091553, 2.6099982261657715, 2.616349697113037, 2.6184942722320557, 2.613104820251465, 2.616447687149048, 2.6253795623779297, 2.624751329421997, 2.6295382976531982, 2.622236490249634], [2.6768617630004883, 2.6661813259124756, 2.666130781173706, 2.6890904903411865, 2.6719629764556885, 2.6706390380859375, 2.6777257919311523, 2.6983120441436768, 2.6857376098632812, 2.681218147277832], [2.6968958377838135, 2.6825764179229736, 2.6991846561431885, 2.7014880180358887, 2.6967198848724365, 2.6666014194488525, 2.677534580230713, 2.6682004928588867, 2.678260326385498, 2.693143844604492], [2.684039354324341, 2.6933815479278564, 2.6817476749420166, 2.6840598583221436, 2.678375244140625, 2.6787102222442627, 2.6696815490722656, 2.6632368564605713, 2.659223794937134, 2.66658616065979], [2.6872966289520264, 2.6849584579467773, 2.6937217712402344, 2.6924030780792236, 2.695941686630249, 2.693232297897339, 2.675079822540283, 2.673718214035034, 2.679757833480835, 2.6758344173431396], [2.6647632122039795, 2.6773505210876465, 2.7109627723693848, 2.708261728286743, 2.6851046085357666, 2.702397584915161, 2.6960697174072266, 2.6719088554382324, 2.680467128753662, 2.6749253273010254], [2.6774580478668213, 2.6777021884918213, 2.6877317428588867, 2.694568157196045, 2.6855320930480957, 2.6988439559936523, 2.690925121307373, 2.6924080848693848, 2.700089931488037, 2.6817266941070557], [2.6789307594299316, 2.7029922008514404, 2.6912152767181396, 2.686741590499878, 2.696312427520752, 2.6809394359588623, 2.7043559551239014, 2.7008140087127686, 2.6771645545959473, 2.7056989669799805], [2.677128791809082, 2.704963207244873, 2.7002322673797607, 2.6885523796081543, 2.6807427406311035, 2.6909539699554443, 2.6897425651550293, 2.6839799880981445, 2.67392897605896, 2.6939990520477295], [2.734900712966919, 2.7404048442840576, 2.746511697769165, 2.7427074909210205, 2.764291763305664, 2.7502851486206055, 2.7375223636627197, 2.74737548828125, 2.7373712062835693, 2.7428395748138428], [2.755980968475342, 2.7584924697875977, 2.7735626697540283, 2.7415645122528076, 2.7432944774627686, 2.7404487133026123, 2.7413618564605713, 2.7406656742095947, 2.7437801361083984, 2.737443447113037], [2.7438416481018066, 2.7275450229644775, 2.7524664402008057, 2.7421560287475586, 2.7563998699188232, 2.7524657249450684, 2.7386701107025146, 2.758345127105713, 2.76716947555542, 2.7697155475616455], [2.7597413063049316, 2.7572274208068848, 2.758526563644409, 2.751922607421875, 2.7521908283233643, 2.7351291179656982, 2.7530319690704346, 2.738476037979126, 2.738215684890747, 2.7346854209899902], [2.724250316619873, 2.7196080684661865, 2.7493631839752197, 2.718655824661255, 2.7176733016967773, 2.7392027378082275, 2.7319259643554688, 2.73307204246521, 2.7234389781951904, 2.736084222793579], [2.7445380687713623, 2.729982852935791, 2.718139410018921, 2.75238037109375, 2.746586561203003, 2.7597951889038086, 2.760305881500244, 2.7621216773986816, 2.7430615425109863, 2.7427475452423096], [2.7604799270629883, 2.741859197616577, 2.745877981185913, 2.7501626014709473, 2.7586662769317627, 2.744154214859009, 2.755221366882324, 2.75134015083313, 2.7450942993164062, 2.7609643936157227], [2.745973587036133, 2.760007381439209, 2.755542039871216, 2.737469434738159, 2.733671188354492, 2.7391467094421387, 2.7352263927459717, 2.7341830730438232, 2.7361676692962646, 2.7487518787384033]], "test_losses": [6.206242084503174, 6.001927852630615, 5.856459617614746, 5.777658939361572, 6.198313236236572, 6.154890775680542, 6.329679012298584, 5.550229787826538, 5.982604026794434, 5.847790002822876, 5.954711198806763, 5.797468662261963, 6.719220399856567, 6.143519878387451, 6.040290832519531, 5.74111270904541, 6.080228328704834, 6.474456071853638, 6.038766145706177, 6.125993013381958, 5.769590854644775, 6.142853021621704, 6.411892414093018, 6.197218418121338, 6.014192819595337, 6.4510252475738525, 6.280093669891357, 6.0014848709106445, 6.09529709815979, 6.498344659805298, 6.378331661224365, 5.638647556304932, 6.158994197845459, 6.604257583618164, 6.185381650924683, 6.058077335357666, 5.982123374938965, 6.643953561782837, 6.255486488342285, 6.165161371231079, 5.588250637054443, 5.954087495803833, 6.232001781463623, 5.724272012710571, 6.307539224624634, 6.537714719772339, 6.128115892410278, 6.029804468154907, 6.513573169708252, 6.306257009506226, 5.974275588989258, 6.313838481903076, 5.97234320640564, 6.037593841552734, 5.792632341384888, 6.3421385288238525, 6.342028856277466, 6.139040470123291, 5.862585783004761, 6.328822374343872, 5.652857780456543, 5.9737021923065186, 5.802521467208862, 6.2895801067352295], "test_times": [0.09790492057800293, 0.1023862361907959, 0.09961128234863281, 0.09758925437927246, 0.0994577407836914, 0.10187888145446777, 0.10110044479370117, 0.10111451148986816, 0.10053491592407227, 0.10178112983703613, 0.10094761848449707, 0.10106086730957031, 0.10133647918701172, 0.10428333282470703, 0.10116910934448242, 0.10286474227905273, 0.09949827194213867, 0.09881186485290527, 0.10064411163330078, 0.1112203598022461, 0.10161852836608887, 0.1011190414428711, 0.10225510597229004, 0.10250163078308105, 0.10277414321899414, 0.10357451438903809, 0.10794472694396973, 0.1003730297088623, 0.10147905349731445, 0.10489082336425781, 0.10027909278869629, 0.10097980499267578, 0.10210514068603516, 0.1040644645690918, 0.10714459419250488, 0.10258936882019043, 0.1027066707611084, 0.10519099235534668, 0.10155797004699707, 0.10407590866088867, 0.10459256172180176, 0.10280895233154297, 0.10690689086914062, 0.10378336906433105, 0.10423398017883301, 0.10438036918640137, 0.10245347023010254, 0.10661935806274414, 0.1070551872253418, 0.10523080825805664, 0.10324215888977051, 0.10270810127258301, 0.10724282264709473, 0.10803651809692383, 0.10431575775146484, 0.10616469383239746, 0.10922026634216309, 0.1056513786315918, 0.10674166679382324, 0.10849690437316895, 0.10304498672485352, 0.10710835456848145, 0.10919785499572754, 0.10857319831848145]}