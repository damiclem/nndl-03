{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charlie: one hot encoded characters based text generation\n",
    "\n",
    "This neural network is the simplest among the ones faced in this project. It uses sentences splitted into characters, which are then one hot encoded to provide a computer readable format as network input.\n",
    "\n",
    "First step in the development of this neural network is the definition of its architecture by means of a grid search for a few epochs in order to compute loss and compare it among the parameters tested.\n",
    "\n",
    "Once an architecture has been set and other optimal parameters such as length of the recurrent window and the type of the neural network have been found, the neural network is trained again on the whole dataset for many epochs to develop the final model, saving its weights in checkpoints at regular epochs interval, in order to avoid eventual loss of traning progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from src.dataset import WarAndPeace, OneHotEncode, RandomCrop, ToTensor\n",
    "from src.dataset import split_train_test\n",
    "from src.network import Charlie\n",
    "from src.network import grid_search, save_epochs, load_epochs, train_test_epochs\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import optim, nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CPU device\n",
    "cpu = torch.device('cpu')\n",
    "# Define best device (GPU if available, CPU otherwise)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 32594\n"
     ]
    }
   ],
   "source": [
    "# Make dataset\n",
    "dataset = WarAndPeace('./data/war-and-peace-tolstoj.txt', split_how='chars', min_len=10)\n",
    "# Show dataset length (number of sentences)\n",
    "print('Dataset length:', len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', 'w', 'e', 'l', 'l', ',', ' ', 'p', 'r', 'i', 'n', 'c', 'e', ',', ' ', 's', 'o', ' ', 'g', 'e', 'n', 'o', 'a', ' ', 'a', 'n', 'd', ' ', 'l', 'u', 'c', 'c', 'a', ' ', 'a', 'r', 'e', ' ', 'n', 'o', 'w', ' ', 'j', 'u', 's', 't', ' ', 'f', 'a', 'm', 'i', 'l', 'y', ' ', 'e', 's', 't', 'a', 't', 'e', 's', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'b', 'u', 'o', 'n', 'a', 'p', 'a', 'r', 't', 'e', 's', '.', ' ']\n",
      "['b', 'u', 't', ' ', 'i', ' ', 'w', 'a', 'r', 'n', ' ', 'y', 'o', 'u', ',', ' ', 'i', 'f', ' ', 'y', 'o', 'u', ' ', 'd', 'o', 'n', \"'\", 't', ' ', 't', 'e', 'l', 'l', ' ', 'm', 'e', ' ', 't', 'h', 'a', 't', ' ', 't', 'h', 'i', 's', ' ', 'm', 'e', 'a', 'n', 's', ' ', 'w', 'a', 'r', ',', ' ', 'i', 'f', ' ', 'y', 'o', 'u', ' ', 's', 't', 'i', 'l', 'l', ' ', 't', 'r', 'y', ' ', 't', 'o', ' ', 'd', 'e', 'f', 'e', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'i', 'n', 'f', 'a', 'm', 'i', 'e', 's', ' ', 'a', 'n', 'd', ' ', 'h', 'o', 'r', 'r', 'o', 'r', 's', ' ', 'p', 'e', 'r', 'p', 'e', 't', 'r', 'a', 't', 'e', 'd', ' ', 'b', 'y', ' ', 't', 'h', 'a', 't', ' ', 'a', 'n', 't', 'i', 'c', 'h', 'r', 'i', 's', 't', ' ', 'i', ' ', 'r', 'e', 'a', 'l', 'l', 'y', ' ', 'b', 'e', 'l', 'i', 'e', 'v', 'e', ' ', 'h', 'e', ' ', 'i', 's', ' ', 'a', 'n', 't', 'i', 'c', 'h', 'r', 'i', 's', 't', ' ', 'i', ' ', 'w', 'i', 'l', 'l', ' ', 'h', 'a', 'v', 'e', ' ', 'n', 'o', 't', 'h', 'i', 'n', 'g', ' ', 'm', 'o', 'r', 'e', ' ', 't', 'o', ' ', 'd', 'o', ' ', 'w', 'i', 't', 'h', ' ', 'y', 'o', 'u', ' ', 'a', 'n', 'd', ' ', 'y', 'o', 'u', ' ', 'a', 'r', 'e', ' ', 'n', 'o', ' ', 'l', 'o', 'n', 'g', 'e', 'r', ' ', 'm', 'y', ' ', 'f', 'r', 'i', 'e', 'n', 'd', ',', ' ', 'n', 'o', ' ', 'l', 'o', 'n', 'g', 'e', 'r', ' ', 'm', 'y', ' ', \"'\", 'f', 'a', 'i', 't', 'h', 'f', 'u', 'l', ' ', 's', 'l', 'a', 'v', 'e', ',', \"'\", ' ', 'a', 's', ' ', 'y', 'o', 'u', ' ', 'c', 'a', 'l', 'l', ' ', 'y', 'o', 'u', 'r', 's', 'e', 'l', 'f', '!', ' ']\n",
      "['b', 'u', 't', ' ', 'h', 'o', 'w', ' ', 'd', 'o', ' ', 'y', 'o', 'u', ' ', 'd', 'o', '?', ' ']\n"
     ]
    }
   ],
   "source": [
    "# Show first 3 sentences\n",
    "for i in range(3):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize alphabet (set of available characters)\n",
    "alphabet = set()\n",
    "# Go through each sentence in dataset\n",
    "for i in range(len(dataset)):\n",
    "    # Turn sentence (list of characters) into set\n",
    "    sentence = set(dataset[i])\n",
    "    # Update alphabet\n",
    "    alphabet |= sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36\n",
      "z  c  .  ,  n     s  b  i  r  f  u  :  v  m  ?  w  d  h  e  o  j  g  )  x  l  a  k  p  q  y  ;  \"  (  '  t  ! \n"
     ]
    }
   ],
   "source": [
    "# Show all available characters\n",
    "print(' '.join([str(i).zfill(2) for i in range(len(alphabet))]))  # Index\n",
    "print(' '.join([str(c) + ' ' for c in alphabet]))  # Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation for dataset\n",
    "dataset.transform = transforms.Compose([\n",
    "    OneHotEncode(alphabet),\n",
    "    RandomCrop(7),\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence nr 1 has shape 7 x 37\n",
      "Sentence nr 2 has shape 7 x 37\n",
      "Sentence nr 3 has shape 7 x 37\n"
     ]
    }
   ],
   "source": [
    "# Show first 3 sentences shapes\n",
    "for i in range(3):\n",
    "    print('Sentence nr {:d} has shape {:d} x {:d}'.format(i+1, *dataset[i].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split initial dataset in train dataset and test dataset\n",
    "train_dataset, test_dataset = split_train_test(dataset, 0.8)\n",
    "# Make train dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1000, shuffle=True)\n",
    "# Make test dataloader\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current network parameters (1):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 5, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.0005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.299 in 221 seconds\n",
      "Test done with loss 2.978 in 5 seconds\n",
      "\n",
      "Current network parameters (2):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 5, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.298 in 220 seconds\n",
      "Test done with loss 2.968 in 5 seconds\n",
      "\n",
      "Current network parameters (3):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 5, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.05, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.300 in 220 seconds\n",
      "Test done with loss 3.009 in 5 seconds\n",
      "\n",
      "Current network parameters (4):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 5, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.0005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.297 in 235 seconds\n",
      "Test done with loss 2.991 in 5 seconds\n",
      "\n",
      "Current network parameters (5):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 5, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.298 in 235 seconds\n",
      "Test done with loss 2.972 in 5 seconds\n",
      "\n",
      "Current network parameters (6):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 5, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.05, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.303 in 235 seconds\n",
      "Test done with loss 3.017 in 5 seconds\n",
      "\n",
      "Current network parameters (7):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 4, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.0005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.242 in 210 seconds\n",
      "Test done with loss 2.403 in 5 seconds\n",
      "\n",
      "Current network parameters (8):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 4, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.299 in 210 seconds\n",
      "Test done with loss 3.000 in 5 seconds\n",
      "\n",
      "Current network parameters (9):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 4, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.05, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.300 in 210 seconds\n",
      "Test done with loss 3.027 in 5 seconds\n",
      "\n",
      "Current network parameters (10):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 4, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.0005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.299 in 220 seconds\n",
      "Test done with loss 2.981 in 5 seconds\n",
      "\n",
      "Current network parameters (11):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 4, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.299 in 221 seconds\n",
      "Test done with loss 2.983 in 5 seconds\n",
      "\n",
      "Current network parameters (12):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 4, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.05, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.302 in 220 seconds\n",
      "Test done with loss 3.020 in 5 seconds\n",
      "\n",
      "Current network parameters (13):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 3, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.0005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.230 in 199 seconds\n",
      "Test done with loss 2.262 in 4 seconds\n",
      "\n",
      "Current network parameters (14):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 3, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.297 in 199 seconds\n",
      "Test done with loss 2.992 in 5 seconds\n",
      "\n",
      "Current network parameters (15):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 3, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.05, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.301 in 199 seconds\n",
      "Test done with loss 3.016 in 5 seconds\n",
      "\n",
      "Current network parameters (16):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 3, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.0005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.298 in 207 seconds\n",
      "Test done with loss 2.994 in 5 seconds\n",
      "\n",
      "Current network parameters (17):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 3, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.298 in 206 seconds\n",
      "Test done with loss 2.979 in 5 seconds\n",
      "\n",
      "Current network parameters (18):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 512, net__layers_num: 3, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.05, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.303 in 207 seconds\n",
      "Test done with loss 3.023 in 5 seconds\n",
      "\n",
      "Current network parameters (19):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 5, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.0005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.297 in 187 seconds\n",
      "Test done with loss 2.996 in 4 seconds\n",
      "\n",
      "Current network parameters (20):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 5, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.298 in 187 seconds\n",
      "Test done with loss 2.960 in 4 seconds\n",
      "\n",
      "Current network parameters (21):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 5, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.05, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.300 in 188 seconds\n",
      "Test done with loss 3.024 in 4 seconds\n",
      "\n",
      "Current network parameters (22):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 5, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.0005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.298 in 193 seconds\n",
      "Test done with loss 2.966 in 4 seconds\n",
      "\n",
      "Current network parameters (23):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 5, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.298 in 192 seconds\n",
      "Test done with loss 2.976 in 4 seconds\n",
      "\n",
      "Current network parameters (24):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 5, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.05, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.303 in 192 seconds\n",
      "Test done with loss 3.027 in 4 seconds\n",
      "\n",
      "Current network parameters (25):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 4, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.0005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.259 in 186 seconds\n",
      "Test done with loss 2.553 in 4 seconds\n",
      "\n",
      "Current network parameters (26):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 4, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.299 in 187 seconds\n",
      "Test done with loss 2.981 in 4 seconds\n",
      "\n",
      "Current network parameters (27):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 4, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.05, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.300 in 187 seconds\n",
      "Test done with loss 3.007 in 4 seconds\n",
      "\n",
      "Current network parameters (28):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 4, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.0005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.299 in 189 seconds\n",
      "Test done with loss 2.974 in 4 seconds\n",
      "\n",
      "Current network parameters (29):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 4, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.299 in 189 seconds\n",
      "Test done with loss 2.978 in 4 seconds\n",
      "\n",
      "Current network parameters (30):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 4, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.05, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.302 in 188 seconds\n",
      "Test done with loss 3.030 in 4 seconds\n",
      "\n",
      "Current network parameters (31):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 3, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.0005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.238 in 183 seconds\n",
      "Test done with loss 2.331 in 4 seconds\n",
      "\n",
      "Current network parameters (32):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 3, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.297 in 183 seconds\n",
      "Test done with loss 3.011 in 4 seconds\n",
      "\n",
      "Current network parameters (33):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 3, net__hidden_type: GRU, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.05, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.301 in 183 seconds\n",
      "Test done with loss 3.013 in 4 seconds\n",
      "\n",
      "Current network parameters (34):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 3, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.0005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.297 in 185 seconds\n",
      "Test done with loss 2.974 in 4 seconds\n",
      "\n",
      "Current network parameters (35):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 3, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.005, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.298 in 186 seconds\n",
      "Test done with loss 2.987 in 4 seconds\n",
      "\n",
      "Current network parameters (36):\n",
      "(net: <class 'src.network.Charlie'>, net__input_size: 37, net__hidden_units: 256, net__layers_num: 3, net__hidden_type: LSTM, optim: <class 'torch.optim.adam.Adam'>, optim__weight_decay: 0.05, loss_fn: <class 'torch.nn.modules.loss.CrossEntropyLoss'>)\n",
      "Training done with loss 0.302 in 185 seconds\n",
      "Test done with loss 3.035 in 4 seconds\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f263bc0ba62e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Store parameters to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     save_epochs(\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data/charlie/hyper.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "# Enable hyperparameters cross validation\n",
    "HYPER_TRAIN = True\n",
    "\n",
    "# Do only if hyperparameters training is enabled\n",
    "if HYPER_TRAIN:\n",
    "    \n",
    "    # Make parameters training\n",
    "    params, train_losses, train_times, test_losses, test_times = grid_search(\n",
    "        train_dl=train_dataloader, test_dl=test_dataloader,\n",
    "        net=[Charlie], net__input_size=[len(alphabet)], net__hidden_units=[512, 256], net__layers_num=[5, 4, 3], net__hidden_type=['GRU', 'LSTM'],\n",
    "        optim=[optim.Adam], optim__weight_decay=[5e-4, 5e-3, 5e-2],\n",
    "        loss_fn=[nn.CrossEntropyLoss],\n",
    "        num_epochs=10,\n",
    "        verbose=True,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Store parameters to disk\n",
    "    save_epochs(\n",
    "        path='data/charlie/hyper.json',\n",
    "        params=params,\n",
    "        train_losses=train_losses,\n",
    "        train_times=train_times,\n",
    "        test_losses=test_losses,\n",
    "        test_times=test_times\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters from disk\n",
    "params, train_losses, train_times, test_losses, test_times = load_epochs(\n",
    "    path='data/charlie/hyper.json'\n",
    ")\n",
    "\n",
    "# Print parameters\n",
    "for i in range(len(params)):\n",
    "    # Print current parameters combination\n",
    "    print('Current network parameters ({:d}):'.format(i + 1))\n",
    "    print('(' + ', '.join(['{:}: {:}'.format(kw, arg) for kw, arg in params[i].items()]) + ')')\n",
    "    # Print train step\n",
    "    print('Training done with loss {:.03f}'.format(train_losses[i]), end=' ')\n",
    "    print('in {:.0f} seconds'.format(train_times[i]))\n",
    "    # Print test step\n",
    "    print('Test done with loss {:.03f}'.format(test_losses[i]), end=' ')\n",
    "    print('in {:.0f} seconds'.format(test_times[i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot execution times vs loss\n",
    "\n",
    "# Initialize plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(21, 7))\n",
    "\n",
    "# Set title and labels\n",
    "axs[0].set_title('Training time vs loss')\n",
    "axs[0].set_xlabel('Time (seconds)')\n",
    "axs[0].set_ylabel('Loss (float)')\n",
    "# Make plot\n",
    "axs[0].scatter(x=train_times, y=train_losses)\n",
    "# Loop through every marker in plot\n",
    "for i in range(len(params)):\n",
    "    # Add correction for text\n",
    "    corr = 0.01\n",
    "    # Add marker index on point\n",
    "    axs[0].annotate(str(i+1), xy=(train_times[i] + corr, train_losses[i] + corr))\n",
    "\n",
    "# Set title and labels\n",
    "axs[1].set_title('Test time vs loss')\n",
    "axs[1].set_xlabel('Time (seconds)')\n",
    "axs[1].set_ylabel('Loss (float)')\n",
    "# Make plot\n",
    "axs[1].scatter(x=test_times, y=test_losses)\n",
    "# Loop through every marker in plot\n",
    "for i in range(len(params)):\n",
    "    # Define a little correction to point placement\n",
    "    corr = 0.01\n",
    "    # Add marker index on point\n",
    "    axs[1].annotate(str(i+1), xy=(test_times[i] + corr, test_losses[i] + corr))\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate new network\n",
    "net = Charlie(input_size=len(alphabet), hidden_units=512, layers_num=3, hidden_type='GRU')\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = optim.Adam(net.params(), weight_decay=0.005)\n",
    "# Define loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define number of epochs\n",
    "num_epochs = 1000000\n",
    "# Define number of epochs per checkpoint\n",
    "save_after = 100\n",
    "\n",
    "# Make train and test\n",
    "train_test_epochs(\n",
    "    net=net,\n",
    "    train_dl=train_dataloader,\n",
    "    test_dl=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    save_after=save_after,\n",
    "    net_path='data/charlie/model.pth',\n",
    "    epochs_path='data/charlie/train.json',\n",
    "    verbose=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
